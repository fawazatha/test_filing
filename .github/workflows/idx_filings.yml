name: IDX Filings

on:
  schedule:
    - cron: "0 */2 * * *"
  workflow_dispatch:
    inputs:
      mode:
        description: "Run mode"
        type: choice
        required: true
        default: lookback
        options: [single_day, range, lookback]
      date:
        description: "YYYYMMDD (single_day)"
        required: false
      start_hhmm:
        description: "HH:MM WIB (single_day)"
        required: false
      end_hhmm:
        description: "HH:MM WIB (single_day)"
        required: false
      from_date:
        description: "YYYYMMDD (range)"
        required: false
      to_date:
        description: "YYYYMMDD (range)"
        required: false
      window_minutes:
        description: "Lookback minutes (lookback)"
        required: false
        default: "120"
      upload_to_supabase:
        description: "Upload filings to Supabase? (needs secrets)"
        type: boolean
        default: false
      table:
        description: "Supabase table (if uploading)"
        required: false
        default: "idx_filings"
      verbose:
        description: "Verbose logs?"
        type: boolean
        default: true

env:
  PYTHONPATH: src
  TZ: Asia/Jakarta
  OVERLAP_MINUTES: "1"

concurrency:
  group: idx-filings-manual
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Pre-clean
        run: |
          rm -rf downloads/idx-format downloads/non-idx-format || true
          rm -rf data/*.json alerts/*.json alerts_inserted alerts_not_inserted artifacts/*.zip || true
          mkdir -p downloads/idx-format downloads/non-idx-format data alerts artifacts

      - name: Compute run timestamp (WIB)
        id: ts
        run: echo "stamp=$(date +'%Y%m%d-%H%M%S')" >> "$GITHUB_OUTPUT"

      - name: Run orchestrator
        env:
          # ===== App secrets =====
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

          # (Optional) HTTP proxy just for IDX fetch/downloader
          HTTP_PROXY:  ${{ secrets.PROXY }}
          HTTPS_PROXY: ${{ secrets.PROXY }}

          # IMPORTANT: don't proxy Supabase & AWS (SES/S3/etc.)
          NO_PROXY: "localhost,127.0.0.1,supabase.co,.supabase.co,amazonaws.com,.amazonaws.com"

          # ===== AWS / SES (for emailing alerts) =====
          AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION:            ${{ secrets.AWS_REGION }}           # e.g. ap-southeast-3
          SES_FROM_EMAIL:        ${{ secrets.SES_FROM_EMAIL }}       # e.g. "Ops Bot <no-reply@yourdomain.com>"

          # Recipients (comma-separated). Must be verified if SES is sandbox.
          ALERT_TO_EMAIL_INSERTED:     ${{ secrets.ALERT_TO_EMAIL }}
          ALERT_TO_EMAIL_NOT_INSERTED: ${{ secrets.ALERT_TO_EMAIL }}
          # (Optional)
          # ALERT_CC_EMAIL_INSERTED: ""
          # ALERT_CC_EMAIL_NOT_INSERTED: ""
          # ALERT_BCC_EMAIL_INSERTED: ""
          # ALERT_BCC_EMAIL_NOT_INSERTED: ""
          # ALERT_TITLE_INSERTED: "IDX Alerts — Inserted (DB OK)"
          # ALERT_TITLE_NOT_INSERTED: "IDX Alerts — Not Inserted (Action Needed)"
        shell: bash
        run: |
          set -euo pipefail

          ARGS=( "--zip-artifacts" "--artifact-prefix" "filings" )
          if [[ "${{ inputs.verbose }}" == "true" || "${{ github.event_name }}" == "schedule" ]]; then ARGS+=("-v"); fi

          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            WIN=$(( 120 + ${OVERLAP_MINUTES:-1} ))
            ARGS+=( "--window-minutes" "$WIN" "--upload" "--table" "idx_filings" )
          else
            MODE="${{ inputs.mode }}"
            case "$MODE" in
              single_day)
                [[ -z "${{ inputs.date }}" || -z "${{ inputs.start_hhmm }}" || -z "${{ inputs.end_hhmm }}" ]] && { echo "::error::single_day requires date/start/end"; exit 1; }
                ARGS+=( "--date" "${{ inputs.date }}" "--start-hhmm" "${{ inputs.start_hhmm }}" "--end-hhmm" "${{ inputs.end_hhmm }}" )
                ;;
              range)
                [[ -z "${{ inputs.from_date }}" || -z "${{ inputs.to_date }}" ]] && { echo "::error::range requires from_date/to_date"; exit 1; }
                ARGS+=( "--from-date" "${{ inputs.from_date }}" "--to-date" "${{ inputs.to_date }}" )
                ;;
              lookback|*)
                WIN="${{ inputs.window_minutes || '120' }}"
                ARGS+=( "--window-minutes" "$WIN" )
                ;;
            esac
            if [[ "${{ inputs.upload_to_supabase }}" == "true" ]]; then
              ARGS+=( "--upload" "--table" "${{ inputs.table }}" )
            fi
          fi

          # Turn on emailing step (will auto-skip if folders empty / no recipients)
          ARGS+=( "--email-alerts" )
          # Optional: attachment budget (raw SES limit 10MB; keep headroom for headers/body)
          # ARGS+=( "--email-attach-budget" "7500000" )

          echo "python -m pipeline.orchestrator ${ARGS[*]}"
          python -m pipeline.orchestrator "${ARGS[@]}"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: filings-manual-${{ steps.ts.outputs.stamp }}-run${{ github.run_number }}
          path: |
            artifacts/*.zip
            data/*.json
            alerts/*.json
            alerts_inserted/*.json
            alerts_not_inserted/*.json
          if-no-files-found: warn
          retention-days: 14
          compression-level: 6
