name: IDX Filings

on:
  schedule:
    - cron: "0 */2 * * *"
  workflow_dispatch:
    inputs:
      mode:
        description: "Run mode"
        type: choice
        required: true
        default: lookback
        options: [single_day, range, lookback]
      date:
        description: "YYYYMMDD (single_day)"
        required: false
      start_hhmm:
        description: "HH:MM WIB (single_day)"
        required: false
      end_hhmm:
        description: "HH:MM WIB (single_day)"
        required: false
      from_date:
        description: "YYYYMMDD (range)"
        required: false
      to_date:
        description: "YYYYMMDD (range)"
        required: false
      window_minutes:
        description: "Lookback minutes (lookback)"
        required: false
        default: "120"
      upload_to_supabase:
        description: "Upload filings to Supabase? (needs secrets)"
        type: boolean
        default: false
      table:
        description: "Supabase table (if uploading)"
        required: false
        default: "idx_filings"
      # ==== NEW: Articles & News ====
      generate_articles:
        description: "Generate articles.jsonl from filings?"
        type: boolean
        default: true
      upload_news:
        description: "Upload articles to Supabase idx_news?"
        type: boolean
        default: true
      news_table:
        description: "Supabase news table"
        required: false
        default: "idx_news"
      # ==== NEW: LLM ====
      use_llm:
        description: "Use LLM for summarization/classification (if API key present)"
        type: boolean
        default: true
      llm_provider:
        description: "LLM provider (auto if blank)"
        required: false
        default: ""
      llm_model:
        description: "LLM model name (optional)"
        required: false
        default: ""
      prefer_symbol:
        description: "Prefer 'symbol' over 'tickers' when both exist"
        type: boolean
        default: true
      verbose:
        description: "Verbose logs?"
        type: boolean
        default: true

env:
  PYTHONPATH: src
  TZ: Asia/Jakarta
  OVERLAP_MINUTES: "1"

concurrency:
  group: idx-filings-manual
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Pre-clean
        run: |
          rm -rf downloads/idx-format downloads/non-idx-format || true
          rm -rf data/*.json data/*.jsonl alerts/*.json alerts_inserted alerts_not_inserted artifacts/*.zip || true
          mkdir -p downloads/idx-format downloads/non-idx-format data alerts artifacts

      - name: Compute run timestamp (WIB)
        id: ts
        run: echo "stamp=$(date +'%Y%m%d-%H%M%S')" >> "$GITHUB_OUTPUT"

      - name: Run orchestrator
        env:
          # ===== App secrets =====
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

          # (Optional) HTTP proxy just for IDX fetch/downloader
          HTTP_PROXY:  ${{ secrets.PROXY }}
          HTTPS_PROXY: ${{ secrets.PROXY }}

          # IMPORTANT: don't proxy Supabase & AWS (SES/S3/etc.)
          NO_PROXY: "localhost,127.0.0.1,supabase.co,.supabase.co,amazonaws.com,.amazonaws.com"

          # ===== AWS / SES (for emailing alerts) =====
          AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION:            ${{ secrets.AWS_REGION }}           # e.g. ap-southeast-3
          SES_FROM_EMAIL:        ${{ secrets.SES_FROM_EMAIL }}       # e.g. "Ops Bot <no-reply@yourdomain.com>"

          # Recipients (comma-separated). Must be verified if SES is sandbox.
          ALERT_TO_EMAIL_INSERTED:     ${{ secrets.ALERT_TO_EMAIL }}
          ALERT_TO_EMAIL_NOT_INSERTED: ${{ secrets.ALERT_TO_EMAIL }}

          # ===== (Optional) LLM keys (any subset works) =====
          GROQ_API_KEY:   ${{ secrets.GROQ_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          LLM_PROVIDER:   ${{ inputs.llm_provider }}
          GROQ_MODEL:     ${{ inputs.llm_model }}
          OPENAI_MODEL:   ${{ inputs.llm_model }}
          GEMINI_MODEL:   ${{ inputs.llm_model }}
        shell: bash
        run: |
          set -euo pipefail

          ARGS=( "--zip-artifacts" "--artifact-prefix" "filings" "--email-alerts" )

          # Verbose?
          if [[ "${{ inputs.verbose }}" == "true" || "${{ github.event_name }}" == "schedule" ]]; then
            ARGS+=("-v")
          fi

          # Window selection
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            # default scheduled run: lookback with slight overlap + upload filings
            WIN=$(( 120 + ${OVERLAP_MINUTES:-1} ))
            ARGS+=( "--window-minutes" "$WIN" "--upload" "--table" "idx_filings" )
          else
            MODE="${{ inputs.mode }}"
            case "$MODE" in
              single_day)
                [[ -z "${{ inputs.date }}" || -z "${{ inputs.start_hhmm }}" || -z "${{ inputs.end_hhmm }}" ]] && { echo "::error::single_day requires date/start/end"; exit 1; }
                ARGS+=( "--date" "${{ inputs.date }}" "--start-hhmm" "${{ inputs.start_hhmm }}" "--end-hhmm" "${{ inputs.end_hhmm }}" )
                ;;
              range)
                [[ -z "${{ inputs.from_date }}" || -z "${{ inputs.to_date }}" ]] && { echo "::error::range requires from_date/to_date"; exit 1; }
                ARGS+=( "--from-date" "${{ inputs.from_date }}" "--to-date" "${{ inputs.to_date }}" )
                ;;
              lookback|*)
                WIN="${{ inputs.window_minutes || '120' }}"
                ARGS+=( "--window-minutes" "$WIN" )
                ;;
            esac
            if [[ "${{ inputs.upload_to_supabase }}" == "true" ]]; then
              ARGS+=( "--upload" "--table" "${{ inputs.table }}" )
            fi
          fi

          # Prefer symbol?
          if [[ "${{ inputs.prefer_symbol }}" == "true" ]]; then
            ARGS+=( "--prefer-symbol" )
          fi

          # ==== NEW: Articles generation ====
          GEN_ART="${{ inputs.generate_articles }}"
          UP_NEWS="${{ inputs.upload_news }}"
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            # default on for schedule
            GEN_ART="true"
            UP_NEWS="true"
          fi
          if [[ "$GEN_ART" == "true" ]]; then
            ARGS+=( "--generate-articles" "--articles-out" "data/articles.jsonl" )
          fi

          # ==== NEW: LLM toggling ====
          USE_LLM="${{ inputs.use_llm }}"
          # auto-enable if any key present and user allowed
          if [[ "$USE_LLM" == "true" ]]; then
            if [[ -n "${GROQ_API_KEY:-}" || -n "${OPENAI_API_KEY:-}" || -n "${GEMINI_API_KEY:-}" ]]; then
              ARGS+=( "--use-llm" )
              # pass provider/model if given (they are optional; orchestrator has defaults)
              if [[ -n "${LLM_PROVIDER:-}" ]]; then ARGS+=( "--llm-provider" "${LLM_PROVIDER}" ); fi
              if [[ -n "${GROQ_MODEL:-}" || -n "${OPENAI_MODEL:-}" || -n "${GEMINI_MODEL:-}" ]]; then
                # prefer explicit llm_model input (wired above to all env names)
                MODEL="${GROQ_MODEL:-${OPENAI_MODEL:-${GEMINI_MODEL:-}}}"
                if [[ -n "$MODEL" ]]; then ARGS+=( "--llm-model" "$MODEL" ); fi
              fi
            else
              echo "::notice::USE_LLM requested but no LLM API key found; continuing without LLM."
            fi
          fi

          # ==== NEW: Upload news ====
          if [[ "$UP_NEWS" == "true" ]]; then
            ARGS+=( "--upload-news" "--news-table" "${{ inputs.news_table }}" )
          fi

          echo "python -m pipeline.orchestrator ${ARGS[*]}"
          python -m pipeline.orchestrator "${ARGS[@]}"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: filings-manual-${{ steps.ts.outputs.stamp }}-run${{ github.run_number }}
          path: |
            artifacts/*.zip
            data/*.json
            data/*.jsonl
            alerts/*.json
            alerts_inserted/*.json
            alerts_not_inserted/*.json
          if-no-files-found: warn
          retention-days: 14
          compression-level: 6
